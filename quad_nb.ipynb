{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcdb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from quad import loadQuad, Quads #custom class for quad data\n",
    "import tdt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823b8af",
   "metadata": {},
   "source": [
    "### Load data for given animal/date \n",
    "(Diego = Subj. 1, Pacho = Subj. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad.ml2_dat_list[0]['Trial2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_animal_dict = {\n",
    "    'Pancho': ['251118','251119','251120'],\n",
    "    'Diego': ['251113','251114','251118']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal, dates_list in date_animal_dict.items():\n",
    "    for date in dates_list:\n",
    "        print(f'###### Doing {animal}, {date} ######')\n",
    "        quad = loadQuad(animal,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'Diego'\n",
    "date = '251118'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Change paths to local dirs in this function >>\n",
    "quad = loadQuad(animal, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55edf4d",
   "metadata": {},
   "source": [
    "### Check out data structures\n",
    "- ```quad.prettyBeh``` is the data loaded out of monkey logic\n",
    "\n",
    "- ```quad.prettyTdt``` is the raw data from our tdt recording system\n",
    "    - This includes LFP and raw voltage signal but these are not included for sake of file sizes\n",
    "\n",
    "- ```quad.Dat``` is the merged dataframe, pulls information from Beh and combines it with timing precision in Tdt\n",
    "\n",
    "- ```quad.SpikeTimes``` is dataframe with spike times loaded from kilosort. These have been automatically clustered by ks and manually curated for 'questionable' spikes.\n",
    "\n",
    "** All timing relating things are handled automatically to align event codes with kilosort spike times. Note that 'photodiode_time' in Tdt/Dat is the most correct timing to align with kilosort. \n",
    "\n",
    "** 'sample_index' is also the most accurate indexing variable, with one 'sample_index' per sample that the monkey actually saw (whether they held fixation or not). Sample index DOES NOT include cases where no sample was shown (i.e. broke fixation during the 200ms fixation period). In the tdt data you will see instances of this where it looks like 'fix_cue' followed immediately by 'sample_off' and 'timeout'. The fact that it says 'sample_off' (even with no 'sample_on') is just an unintended part of the monkeylogic code (i.e. it runs toggleobject(sample,'status','off') whether or not there is a toggleobject(sample,'status,'on))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad.prettyBeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad.prettyTdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ddffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad.Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d478ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdt_stim_inds = quad.prettyTdt['stim_index'].dropna().to_numpy()\n",
    "beh_stim_inds = quad.prettyBeh['stim_index'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba38264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad.spikeTimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b8bd9",
   "metadata": {},
   "source": [
    "### Plotting!\n",
    "\n",
    "I have included two plot functions, one to make a PSTH and one to make a raster. Functions have descriptions for use under definition. The main thing to know is what to do with ```params```\n",
    "\n",
    "```params``` should be a dict formatted with a column name and a list of entries in that column you want to keep. The plotting functions will then filter the data to match those parameters. The PSTH plot also has a 'group_by' argument which you can use to group and average activity over different variables. Examples below.\n",
    "\n",
    "** Note right now the plotting functions can only align to 'sample_on', the code shouldn't be too hard to write for other trial events, but wasn't sure if you would end up needing that functionality.\n",
    "\n",
    "** All plotting functions return a dict of figs indexed by 'unit_index'. The titles have the channel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot PSTH\n",
    "conditions_plot = list(range(1,50))\n",
    "params = {\n",
    "    'condition': conditions_plot, #plot only for these conditions\n",
    "    'fixation_success_binary': [True] #only plot when fixation is successful\n",
    "    #You can filter by any column/value pair here, as long as the column is present in 'Dat'\n",
    "}\n",
    "channel = 187\n",
    "fig_dict = quad.plotPSTH(channel, params, group_by='fixation_success_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot raster\n",
    "channel = 187\n",
    "\n",
    "params = {\n",
    "'fixation_success_binary': [True]\n",
    "# 'stim_index': quad.prettyBeh['stim_index'].to_numpy()[np.r_[0:200, -200:-1]]\n",
    "}\n",
    "\n",
    "fig_dict = quad.plotRaster(channel,params, window = (.4,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355c7ea",
   "metadata": {},
   "source": [
    "### Additional functions in quad.py\n",
    "\n",
    "```filter_df``` = function to filter df given dict (structured like params above). Filters df by column/value pairs and returns the filter df. Useful for plotting.\n",
    "\n",
    "```group_and_average``` = useful function for plotting, will take dat and group by unique values in a particular column and then average over 'spike_counts'. Right now, for example you could make one psth for each unique stimulus. If you wanted to do something like regular vs irregular though, you could edit this function to be more flexible to that.\n",
    "\n",
    "```getChannelNumOrRegionName``` = A flexible function for getting the channels associated with a region or the region associated with a channel. You can look at the bottom of the file 'MAP_CHANNEL_TO_REGION' is a dict with all this info."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
